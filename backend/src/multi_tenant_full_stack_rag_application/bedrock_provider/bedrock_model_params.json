{
    "amazon.nova-micro-v1:0": {
        "display_name": "Nova Micro",
        "default_paths": [
            "textGenerationConfig.maxTokenCount.default",
            "textGenerationConfig.temperature.default",
            "textGenerationConfig.topP.default",
            "textGenerationConfig.stopSequences.default"
        ],
        "inputText": "",
        "inferenceConfig": {
            "max_tokens": {
                "default": 512,
                "max": 5120,
                "min": 0,
                "type": "int"
            },
            "temperature": {
                "default": 0,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "top_p": {
                "default": 1,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "stop_sequences": {
                "default": [],
                "type": "json"
            }
        }
    },
    "amazon.nova-lite-v1:0": {
        "display_name": "Nova Lite",
        "default_paths": [
            "textGenerationConfig.maxTokenCount.default",
            "textGenerationConfig.temperature.default",
            "textGenerationConfig.topP.default",
            "textGenerationConfig.stopSequences.default"
        ],
        "inputText": "",
        "inferenceConfig": {
            "max_tokens": {
                "default": 512,
                "max": 5120,
                "min": 0,
                "type": "int"
            },
            "temperature": {
                "default": 0,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "top_p": {
                "default": 1,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "stop_sequences": {
                "default": [],
                "type": "json"
            }
        }
    },
    "amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "default_paths": [
            "textGenerationConfig.maxTokenCount.default",
            "textGenerationConfig.temperature.default",
            "textGenerationConfig.topP.default",
            "textGenerationConfig.stopSequences.default"
        ],
        "inputText": "",
        "inferenceConfig": {
            "max_tokens": {
                "default": 512,
                "max": 5120,
                "min": 0,
                "type": "int"
            },
            "temperature": {
                "default": 0,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "top_p": {
                "default": 1,
                "max": 1,
                "min": 0,
                "type": "float"
            },
            "stop_sequences": {
                "default": [],
                "type": "json"
            }
        }
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "default_paths": [
            "anthropic_version",
            "max_tokens.default",
            "temperature.default",
            "top_k.default",
            "top_p.default",
            "stop_sequences.default"
        ],
        "messages": "",
        "anthropic_version":"",
        "max_tokens": {
            "max": 4096,
            "default": 4096,
            "min": 0,
            "type": "int"
        },
        "temperature": {
            "default": 0.0,
            "max": 1,
            "min": 0,
            "type": "float"
        },
        "top_k": {
            "default": 250,
            "max": 500,
            "min": 0,
            "type": "int"
        },
        "top_p": {
            "default": 1,
            "max": 1,
            "min": 0,
            "type": "float"
        },
        "stop_sequences": {
            "default": ["Human"],
            "type": "json"
        }
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "default_paths": [
            "anthropic_version",
            "max_tokens.default",
            "temperature.default",
            "top_k.default",
            "top_p.default",
            "stop_sequences.default"
        ],
        "messages": "",
        "anthropic_version":"",
        "max_tokens": {
            "max": 4096,
            "default": 4096,
            "min": 0,
            "type": "int"
        },
        "temperature": {
            "default": 0.0,
            "max": 1,
            "min": 0,
            "type": "float"
        },
        "top_k": {
            "default": 250,
            "max": 500,
            "min": 0,
            "type": "int"
        },
        "top_p": {
            "default": 1,
            "max": 1,
            "min": 0,
            "type": "float"
        },
        "stop_sequences": {
            "default": ["Human"],
            "type": "json"
        }
    },
    "meta.llama3-2-11b-instruct-v1:0": {
        "display_name": "Llama 3.2 11B",
        "default_paths": [
            "max_new_tokens.default",
            "temperature.default",
            "top_p.default"
        ],
        "max_new_tokens": {
            "max": 4096,
            "default": 1024,
            "min": 0,
            "type": "int"
        },
        "temperature": {
            "default": 0.5,
            "max": 1,
            "min": 0,
            "type": "float"
        },
        "top_p": {
            "default": 0.9,
            "max": 1,
            "min": 0,
            "type": "float"
        }
    }
}